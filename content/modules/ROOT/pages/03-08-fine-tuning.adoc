= AI Model Fine-Tuning
include::_attributes.adoc[]

== Goals of this lab

As Parasol Insurance embraces the era of AI, we face a unique challenge: leveraging cutting-edge AI technology while maintaining strict control over our proprietary data and processes. This journey requires us to develop in-house AI capabilities that are as powerful as they are secure. The goal of this lab is to show you as a developer how to use open source AI tooling to fine-tune a foundation model using Parasol's proprietary data, producing an optimized and efficient LLM that can be used across a variety of use cases at Parasol. In this lab, you will:

* Explore *fine-tuning* techniques for AI models, incorporating Parasol's unique insurance expertise into LLMs
* Learn how to create and utilize a *custom knowledge base* for training AI models with organization-specific scenarios and regulations
* Learn how the https://arxiv.org/abs/2403.01081[*LAB methodology*] generates synthetic training data and produces a specialized model while keeping data in-house
* Gain hands-on experience in *serving* a customized AI model
* Understand the *benefits and limitations* of fine-tuning compared to other AI customization methods

=== Enhancing AI Models: RAG vs Fine-Tuning

When customizing AI models, two techniques stand out: Retrieval-Augmented Generation (RAG) and fine-tuning.

* *Fine-tuning* excels when you need precise, controlled outputs for specialized tasks using curated data. It's ideal for applications where security and compliance require embedding all data within the model. Fine-tuning is also suitable when you have clear use cases with specific task requirements.

image::03/08-rag-vs-finetuning-1.png[RAG vs Fine-Tuning]

* In contrast, *Retrieval-Augmented Generation (RAG)* is best when you need real-time access to dynamic knowledge bases, especially in environments with constantly updating information. RAG allows for scalability and handles out-of-domain queries effectively without the need for retraining, making it quick solution for improving model output. However, by providing contextual information to the model for each prompt, your expenses and computer resources may be higher than "baking-in" information into the model through fine-tuning.

image::03/08-rag-vs-finetuning-2.png[RAG vs Fine-Tuning]

== Get Started with Fine-Tuning

Now that we've outlined Parasol's AI needs, let's dive into the process of meeting them. In this section, we'll explore how to use the InstructLab project to tailor a foundation language model to Parasol's specific requirements, focusing on the key areas we've identified.

=== What is InstructLab?

https://instructlab.ai/[InstructLab^] is an open-source project designed to enhance large language models (LLMs) for use in generative AI applications. It provides a novel approach to model alignment and fine-tuning, allowing developers and domain experts to add new knowledge and skills to pre-trained models with minimal data and computational resources. Key features of InstructLab include:

* A taxonomy-driven approach to curating training data
* Large-scale synthetic data generation
* Iterative alignment tuning for continuous model improvement

image::03/08-instructlab-components.png[InstructLab Overview]

InstructLab is particularly useful for organizations that want to leverage private AI and keep their data in-house while still benefiting from state-of-the-art language models, without needing AI/ML or data science expertise.

As you work with InstructLab, you will see the terms _Skills_ and _Knowledge_. What is the difference between Skills and Knowledge? A simple analogy is to think of a skill as teaching someone how to fish. Knowledge, on the other hand, is knowing that the best place to catch a Bass is when the sun is setting while casting your line near the trunk of a tree along the bank.

video::4lguiHJHgfo[youtube]

== Environment information

If you are using the customized version of the instructions, the information below will render properly. If not, you will see placeholder values instead.

* Your account id: `{user}`
* Your password: `{password}`

== Go to your project

* The {rhoai} Dashboard URL for our shared environment:
** https://rhods-dashboard-redhat-ods-applications.{openshift_cluster_ingress_domain}/[https://rhods-dashboard-redhat-ods-applications.{openshift_cluster_ingress_domain}/,window=_blank]
* Click on the `Login with OpenShift` button:
+
[.bordershadow]
image::02/02-01-login3.png[width=50%]
* Enter your credentials (as detailed above)
+

* First, in the {rhoai} Dashboard application, navigate to the Data Science Projects menu on the left:

+
[.bordershadow]
image::02/02-02-ds-proj-nav.png[]

* Then, open the project called {user}.

* Inside the project you should see a `ilab` workbench has been pre-created. You can ignore the unknown container size warning.

+
[.bordershadow]
image::03/08-ilab-workbench.png[]

* To connect to the `ilab` workbench, click the **Open** link

== Chatting with the Un-Finetuned Model

* Click on the `Terminal` icon in the Launcher:
+
[.bordershadow]
image::03/08-launcher.png[]

* After the terminal appears, enter the following on the command prompt to initialize the `ilab` command-line interface:
+
[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab config init --non-interactive --model-path mistralai/Mistral-7B-Instruct-v0.2
----

* After the `config.yaml` file is generated, enter the following on the command prompt to start chatting with a pre-deployed fine-tuned model:
+
[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab model chat --endpoint-url {unfinetuned-endpoint} --max-tokens 2048 -gm
----

* The following should appear on the terminal:
+
[source,bash]
----
╭────────────────────────────── system ──────────────────────────────╮
│ Welcome to InstructLab Chat w/ /DATA/MODEL.GGUF (type /h for help) │
╰────────────────────────────────────────────────────────────────────╯
----

* Start chatting with the fine-tuned model. Ask the model some Parasol-specific questions:

** Do Parasol insurance policies include loss of income cover if the insured driver is at fault?

** Will Parasol insurance cover the cost of car rental if my car is undriveable as a result of an accident?

** What is Apex plus from parasol insurance?

** Who owns parasol insurance company?

* Notice how the answers do not seem to make sense.

* When you are done, type `exit` to exit from the chat.

== Model Fine-Tuning for the Insurance Organization

In the next few sections, we'll walk through the process of fine-tuning an AI model using InstructLab. We'll start by setting up our environment, generating synthetic training data, training the model, and then interacting with it. We will build upon that and delve further into the biggest insurance company in North America, Parasol, which has the most extensive customer base. Parasol Insurance gets many requests to process claims, questions about different products, etc. These requests are not just internal but also external.

Parasol Insurance's primary concern is ensuring that its staff is capable of handling such requests and has access to this information through a single interface rather than going through multiple systems to scrape documents and internal portal pages. To this end, you have been tasked with adding knowledge that will aid the following use cases.

* Products and coverage (e.g., providing comprehensive policy and product information)
* Basic knowledge of the Insurance rules (e.g., offering insights on relevant local regulations)
* Responses to general claim questions and remedies (e.g., generating product-specific email templates)

image::03/08-parasol-insurance-chat.png[Parasol Insurance]

=== Preparing the Parasol Insurance Knowledge Base

The approach of fine-tuning a model allows us to shape a language model to better understand a specific domain, and fill in the gaps in its knowledge. The InstructLab taxonomy provides a structured way to guide the model fine-tuning process, enabling us to add domain-specific knowledge to the model in a heirarchical manner, similar to the example below:

image::03/08-instructlab-taxonomy.png[InstructLab Taxonomy]

Your role is crucial in this process. You'll see how to add  a knowledge domain to the LLM using the organization's specific information, knowledge that the LLM doesn't have and is specific to Parasol Insurance.

=== Understanding the Knowledge Structure

Knowledge consists of data and facts and is backed by documents. When you create knowledge for a model, you're giving it additional data to more accurately answer questions. Knowledge contributions in this project contain a few things:

* A file in a https://github.com/rh-rad-ai-roadshow/parasol_knowledge[Git repository^] that holds your information. For example, these repositories can include markdown versions of information on: Parasol products, insurance domain knowledge, claims processing etc.
* A `qna.yaml` file that asks and answers questions about the information in the git repository, with desirable responses.
* An `attribution.txt` that includes the sources for the information used in the `qna.yaml`, which aids in transparency and accountability.

LLMs have inherent limitations that make certain tasks extremely difficult, like doing math problems. They're great at other tasks, like creative writing. And they could be better at things like logical reasoning. However, these limitations can be overcome by providing them with the right knowledge (and skills, https://www.youtube.com/watch?v=_kbq-npuMC0[which InstructLab can also help with^]). An LLM with knowledge helps it create a basis of information that it can learn from, then you can teach it to use this knowledge via the `qna.yaml` files.

In our case we want the LLM to learn more about Parasol Insurance by supplying this specific information in the form of a basic YAML file named `qna.yaml`:

[source,yaml]
----
version: 3<1>
domain: insurance<2>
created_by: sshaaf<3>
seed_examples:<4>
  - context: |<5>
      In the insurance industry, accurately predicting the likelihood of claims is
      essential for risk assessment and policy pricing. However, Parasol insurance
      claims datasets frequently suffer from class imbalance, where the number of
      non-claims instances far exceeds that of actual claims.
    questions_and_answers:
      - question: What is class imbalance in the context of Parasol insurance claims datasets?
        answer: |
          Class imbalance refers to the situation where the number of non-claims
          instances far exceeds that of actual claims, making predictive modeling
          difficult and potentially leading to biased models.
      - question: What types of information are included in the Policyholder Information feature?
        answer: |
          Policyholder Information includes demographic details like age, gender,
          occupation, marital status, and geographical location, which are critical
          for assessing risk.
      # more questions and answers
document_outline: |<6>
  Information about the Parasol insruance claims data glossary, terms and how
  to read and understand claims. The information is related to the Parasol
  insurance internal records and systems.
document:<7>
  repo: https://github.com/rh-rad-ai-roadshow/parasol_knowledge.git
  commit: 07227df21a3a786d15ae5b88ece2c33bd78ee36a
  patterns:<8>
    - Parasol_auto_insurance.md
    - Insurance_claims_data.md
    - teen_driving_rules.md
    - claims_cost_data.md
----

Each `qna.yaml` file requires a minimum of five question-answer pairs. The `qna.yaml` format must include the following fields:

<1> `version`: Defines the InstructLab taxonomy schema version
<2> `domain`: Category of the knowledge
<3> `created_by`: The author of the contribution, typically a GitHub username
<4> `seed_examples`: Five or more examples sourced from the provided knowledge documents, representing a `question` for the model and desired `response`
<5> `context`: A chunk of information from the knowledge document.
<6> `document_outline`: An outline of the document containing the knowledge you're adding to the model.
<7> `document`: The source of your knowledge contribution, consisting of a `repo` URL pointing to the knowledge markdown files, and `commit` identifier for the specific commit that contains the files
<8> `patterns`: A list of glob patterns specifying the markdown files in your repository that should be used during training. We have placed all the knowledge documents in the https://github.com/rh-rad-ai-roadshow/parasol_knowledge[parasol-knowledge] repository.

=== Creating the Parasol Insurance Knowledge Base

Now that we understand the constructs of the taxonomy's knowledge, let's go ahead and look at the process of creating a knowledge base, which can be used to train the LLM. This will help our applications that utilize the LLM, and agents directly chatting with the model. Furthermore, it will help with claims processing, fraud detection, or anyone who would like to ask the LLM about products, coverage, laws, and some information about Parasol itself.

==== Create a structure for Parasol insurance knowledge

We should create a knowledge folder structure that we can add to later as we add more knowledge and for our peers to also understand how its structured. Lets create a structure like this `knowledge > economy > finance > insurance > parasol`. Enter the following in the terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
mkdir -p ~/.local/share/instructlab/taxonomy/knowledge/economy/finance/insurance/parasol
----

Perfect, now we have the basic working structure to add in specific knowledge about our organization.

== Curating the Data for our AI Model

Let's now add the following taxonomy knowledge file for Parasol Insurance. Each section of this file addresses different aspects of Parasol's insurance policies:

* Like any insurance company on the planet, data is stored into multiple systems, files etc. Employees at Parasol Insurance either using the system for the first time or using it for e.g. detecting fraud, trying to understand the glossary, acronyms etc. A good example is `Policy ID`, a unique ID for policy in our database systems. The LLM does not know about this. By adding this, we can ensure that once a claims agent or an application asks about a policy ID, the LLM can give reasonable answers and suggestions.

* Information about the Parasol Insurance company, and an overview of product details. This will enable the LLM to give answers on a high level about the different offerings, formulate a context about Parasol Insurance, its history, etc.

* Information specific to policies in relation to the different products. This will help our claims processing agents to ask questions about specific cases and scenarios to the LLM. The LLM should be able to suggest remedies or further knowledge to look into.

=== Create knowledge file

Download {qna-url}[`qna.yaml`^] ino the `parasol` folder. "qna" is short for "questions and answers". To do this, enter the following into the terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
curl -Lo ~/.local/share/instructlab/taxonomy/knowledge/economy/finance/insurance/parasol/qna.yaml {qna-url}
sed -i -e '${/^ *$/d;}'  ~/.local/share/instructlab/taxonomy/knowledge/economy/finance/insurance/parasol/qna.yaml
----

And now lets also create an `attribution.txt` file for citing sources. Enter the following to download {attribution-url}[`attribution.txt`^] to the same folder `parasol`:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
curl -Lo ~/.local/share/instructlab/taxonomy/knowledge/economy/finance/insurance/parasol/attribution.txt {attribution-url}
----

=== Check that the Taxonomy is Recognized by InstructLab

Now that we've added data, let's check that the taxonomy is recognized by InstructLab. This will help us ensure that the data we've added is valid and can be used to generate synthetic training data.

Let's navigate to the home directory:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
cd
----

Run the following command to check the validity of the taxonomy:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab taxonomy diff
----

After running the above command you should be able to see the following output.

[source,bash]
----
Taxonomy in /opt/app-root/src/.local/share/instructlab/taxonomy is valid :)
----

If you do not see output similar to above, you may not have added in all of the Q&A file. This is important as the model will use this file to generate synthetic data in the next section.

== Generating Synthetic Training Data 

Now that we've added some initial data, let's use InstructLab to generate synthetic training data. Large Language Models inherently require a large amount of data to be effective, and it can be difficult to find enough real-world data for a niche domain. However, by using InstructLab, we can generate synthetic data that can be used to train the model.

Because the data generation is going to take some time, we will skip the actual steps in this lab. The data generation command is `ilab data generate`.

The result of this is a number of files which you can inspect in the `~/.local/share/instructlab/datasets` directory. 

== Training the Model with New Data

With our synthetic data generated, we should now be in a position to train the model.  Because we only created 1 sample and due to time constraints we're not going to perform the actual training in this lab.

If we were to do this, we would again use the "ilab" CLI with the "model train" command. Something like `ilab model train --device cuda`. Depending on the hardware available, this can take anywhere from several minutes to several hours or days. Once this process was finished we would then have a model we can serve locally with ilab to test our results.

=== Interacting with the Model

A fine-tuned model has been deployed on the cluster. Let's try to chat with it.

* Enter the following on the command prompt to initialize the `ilab` command-line interface:
+
[.console-input]
[source,bash,subs="+attributes,macros+"]
----
# remove old config file
rm ~/.config/instructlab/config.yaml

ilab config init --non-interactive --model-path rh-rad-ai-roadshow/parasol-chat-ilab19-test
----

* After the `config.yaml` file is generated, enter the following on the command prompt to start chatting with a pre-deployed fine-tuned model:
+
[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab model chat --endpoint-url {finetuned-endpoint} --max-tokens 2048 -gm
----

* The following should appear on the terminal:
+
[source,bash]
----
╭────────────────────────────── system ──────────────────────────────╮
│ Welcome to InstructLab Chat w/ /DATA/MODEL.GGUF (type /h for help) │
╰────────────────────────────────────────────────────────────────────╯
----

* Start chatting with the fine-tuned model. Ask the model some Parasol-specific questions:

** Do Parasol insurance policies include loss of income cover if the insured driver is at fault?

** Will Parasol insurance cover the cost of car rental if my car is undriveable as a result of an accident?

** What is Apex plus from parasol insurance?

** Who owns parasol insurance company?

* Notice how the answers now seem to make sense.

* When you are done, type `exit` to exit from the chat, and `exit` once more to exit from the terminal.

* Switch back to the OpenShift AI dashboard and click on switch for the `ilab` workbench to stop the workbench:
+
[.bordershadow]
image::03/08-stop-workbench.png[]

== InstructLab on RHEL AI

You have tried the community version of InstructLab. A supported version of InstructLab is available on RHEL AI while the community version is available freely that can run on any laptop.

Red Hat Enterprise Linux AI (RHEL AI) is an enterprise-grade gen AI foundation model platform to develop, test, and deploy LLMs for gen AI business use cases.

RHEL AI brings together:

* The Granite family of open source Apache 2.0-licensed large language models (LLMs) with complete transparency on training datasets.

* InstructLab model alignment tooling, which provides a community-driven approach to LLM fine-tuning.

* A bootable image of Red Hat Enterprise Linux, along with gen AI libraries and dependencies such as PyTorch and AI accelerator driver software for NVIDIA, Intel, and AMD.

* Enterprise-level technical support and model intellectual property indemnification provided by Red Hat.

* RHEL AI gives you the trusted Red Hat Enterprise Linux platform and adds the necessary components for you to begin your gen AI journey and see results.